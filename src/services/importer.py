import pandas as pd
import logging
from src.database.db import db
from src.config import config

# ÐœÐ°Ð¿Ð¿Ð¸Ð½Ð³ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº (Excel -> DB)
COLUMN_MAPPING = {
    "Ð’Ñ–Ð´Ð´Ñ–Ð»": "department",
    "ÐÑ€Ñ‚Ð¸ÐºÑƒÐ»": "article",
    "ÐÐ°Ð¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ": "name",
    "ÐŸÐ¾ÑÑ‚Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¸Ðº": "supplier",
    "Ð ÐµÐ·Ð¸Ð´ÐµÐ½Ñ‚": "resident",
    "DP": "cluster",
    "Ð Ð¾Ð·Ñ…Ñ–Ð´, ÐºÑ–Ð».": "sales_qty",
    "Ð Ð¾Ð·Ñ…Ñ–Ð´ Ñ†.Ñ€., Ð³Ñ€Ð½.": "sales_sum",
    "Ð—Ð°Ð»Ð¸ÑˆÐ¾Ðº, ÐºÑ–Ð».": "stock_qty",
    "Ð—Ð°Ð»Ð¸ÑˆÐ¾Ðº, Ð³Ñ€Ð½.": "stock_sum"
}

class ImporterService:
    async def import_file(self, file_path: str) -> int:
        """
        Ð§Ð¸Ñ‚Ð°Ñ” Ñ„Ð°Ð¹Ð», Ñ„Ñ–Ð»ÑŒÑ‚Ñ€ÑƒÑ” Ð´Ð°Ð½Ñ– Ñ‚Ð° Ð¾Ð½Ð¾Ð²Ð»ÑŽÑ” Ð±Ð°Ð·Ñƒ.
        ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ” ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ñ… Ñ‚Ð¾Ð²Ð°Ñ€Ñ–Ð².
        """
        try:
            # 1. Ð§Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            else:
                df = pd.read_excel(file_path)

            # 2. Ð‘Ð°Ð·Ð¾Ð²Ðµ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ
            df = df.dropna(subset=['ÐÑ€Ñ‚Ð¸ÐºÑƒÐ»'])  # ÐÑ€Ñ‚Ð¸ÐºÑƒÐ» Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¹
            df = df.fillna('')

            # 3. Ð¤Ð¾Ñ€Ð¼ÑƒÐ²Ð°Ð½Ð½Ñ ÑˆÐ»ÑÑ…Ñƒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ— (Breadcrumbs)
            def build_path(row):
                hierarchy_cols = ['Ð”ÐµÐ¿Ð°Ñ€Ñ‚Ð°Ð¼ÐµÐ½Ñ‚', 'ÐŸÑ–Ð´Ð´ÐµÐ¿-Ñ‚', 'Ð“Ñ€ÑƒÐ¿Ð°', 'ÐŸÑ–Ð´Ð³Ñ€ÑƒÐ¿Ð°']
                parts = []
                for col in hierarchy_cols:
                    val = str(row.get(col, '')).strip()
                    # Ð†Ð³Ð½Ð¾Ñ€ÑƒÑ”Ð¼Ð¾ '0', 'nan', Ð¿ÑƒÑÑ‚Ñ– Ñ€ÑÐ´ÐºÐ¸
                    if val and val != '0' and val.lower() != 'nan':
                        parts.append(val)
                return "/".join(parts)

            df['category_path'] = df.apply(build_path, axis=1)

            # 4. ÐŸÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð¼Ð°Ð¿Ð¿Ñ–Ð½Ð³Ñƒ
            df = df.rename(columns=COLUMN_MAPPING)

            # Ð—Ð°Ð»Ð¸ÑˆÐ°Ñ”Ð¼Ð¾ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ñ– ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
            valid_cols = list(COLUMN_MAPPING.values()) + ['category_path']
            available_cols = [c for c in valid_cols if c in df.columns]
            df = df[available_cols]

            # 5. ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ñ–Ñ Ñ‚Ð¸Ð¿Ñ–Ð² Ð´Ð°Ð½Ð¸Ñ…
            df['article'] = df['article'].astype(str)
            
            numeric_cols = ['sales_qty', 'sales_sum', 'stock_qty', 'stock_sum', 'department']
            for col in numeric_cols:
                if col in df.columns:
                    # Ð§Ð¸ÑÑ‚Ð¸Ð¼Ð¾ Ñ‡Ð¸ÑÐ»Ð°: "1 234,56" -> 1234.56
                    df[col] = pd.to_numeric(
                        df[col].astype(str).str.replace(',', '.').replace('\xa0', '').replace(' ', ''), 
                        errors='coerce'
                    ).fillna(0)

            # 6. ðŸ”¥ Ð ÐžÐ—Ð£ÐœÐÐ Ð¤Ð†Ð›Ð¬Ð¢Ð ÐÐ¦Ð†Ð¯
            # Ð’Ñ–Ð´ÑÑ–ÑŽÑ”Ð¼Ð¾ "Ð¼ÐµÑ€Ñ‚Ð²Ñ–" Ñ‚Ð¾Ð²Ð°Ñ€Ð¸ Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ .env
            initial_count = len(df)
            
            # Ð›Ð¾Ð³Ñ–ÐºÐ°: Ð—Ð°Ð»Ð¸ÑˆÐ°Ñ”Ð¼Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€, Ð¯ÐšÐ©Ðž (ÐŸÑ€Ð¾Ð´Ð°Ð¶Ñ– >= MIN) ÐÐ‘Ðž (Ð—Ð°Ð»Ð¸ÑˆÐ¾Ðº >= MIN)
            # Ð¢Ð¾Ð±Ñ‚Ð¾, Ð²Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ ÑÐºÑ‰Ð¾ Ð† Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ñ– Ð¼Ð°Ð»Ñ–, Ð† Ð·Ð°Ð»Ð¸ÑˆÐºÑƒ Ð½ÐµÐ¼Ð°Ñ”.
            df = df[ 
                (df['sales_qty'] >= config.MIN_SALES) | 
                (df['stock_qty'] >= config.MIN_STOCK) 
            ]
            
            filtered_count = len(df)
            dead_items = initial_count - filtered_count
            
            if dead_items > 0:
                logging.info(f"ðŸ§¹ Importer: Ð’Ñ–Ð´Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾ {dead_items} Ð¼ÐµÑ€Ñ‚Ð²Ð¸Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ð¹ (Sales<{config.MIN_SALES}, Stock<{config.MIN_STOCK})")

            # 7. ÐŸÑ–Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð¾ Ð²ÑÑ‚Ð°Ð²ÐºÐ¸
            records = df.to_dict('records')
            total = len(records)
            logging.info(f"ðŸ“Š Ð”Ð¾ Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ñƒ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ {total} Ñ€ÑÐ´ÐºÑ–Ð².")

            # 8. ÐŸÐ°ÐºÐµÑ‚Ð½Ð° Ð²ÑÑ‚Ð°Ð²ÐºÐ° (Batch Insert)
            batch_size = 1000
            for i in range(0, total, batch_size):
                batch = records[i:i + batch_size]
                await self._insert_batch(batch)

            return total

        except Exception as e:
            logging.error(f"Import Error: {e}")
            raise e

    async def _insert_batch(self, batch):
        """Ð’ÑÑ‚Ð°Ð²ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ð´Ð°Ð½Ð¸Ñ… Ð² Ð‘Ð”"""
        values = []
        for row in batch:
            values.append((
                row.get('article'), 
                row.get('name'), 
                int(row.get('department', 0)),
                row.get('category_path'), 
                row.get('supplier'), 
                row.get('resident'),
                row.get('cluster'), 
                float(row.get('sales_qty', 0)), 
                float(row.get('sales_sum', 0)),
                float(row.get('stock_qty', 0)), 
                float(row.get('stock_sum', 0))
            ))

        query = """
            INSERT INTO products (
                article, name, department, category_path, supplier, resident, cluster,
                sales_qty, sales_sum, stock_qty, stock_sum, updated_at
            )
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, CURRENT_TIMESTAMP)
            ON CONFLICT (article) DO UPDATE SET
                name = EXCLUDED.name,
                department = EXCLUDED.department,
                category_path = EXCLUDED.category_path,
                supplier = EXCLUDED.supplier,
                resident = EXCLUDED.resident,
                cluster = EXCLUDED.cluster,
                sales_qty = EXCLUDED.sales_qty,
                sales_sum = EXCLUDED.sales_sum,
                stock_qty = EXCLUDED.stock_qty,
                stock_sum = EXCLUDED.stock_sum,
                updated_at = CURRENT_TIMESTAMP;
        """
        await db.pool.executemany(query, values)

importer = ImporterService()