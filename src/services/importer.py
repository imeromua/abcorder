import pandas as pd
import logging
from src.database.db import db

# –°–ª–æ–≤–Ω–∏–∫: –Ø–∫ –∫–æ–ª–æ–Ω–∫–∞ –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –≤ –§–∞–π–ª—ñ -> –Ø–∫ –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –≤ –ë–∞–∑—ñ
COLUMN_MAPPING = {
    "–ê—Ä—Ç–∏–∫—É–ª": "article",
    "–ù–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è": "name",
    "–í—ñ–¥–¥—ñ–ª": "department",
    # –ó–±–∏—Ä–∞—î–º–æ —à–ª—è—Ö –∑ –∫—ñ–ª—å–∫–æ—Ö –∫–æ–ª–æ–Ω–æ–∫, –∞–ª–µ –æ—Å–Ω–æ–≤–Ω–∞ –¥–ª—è –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó —Ü–µ –ì—Ä—É–ø–∞
    # –¢—É—Ç –º–∏ –∑—Ä–æ–±–∏–º–æ —Ö–∏—Ç—Ä—ñ—Å—Ç—å —É –∫–æ–¥—ñ –Ω–∏–∂—á–µ
    "–ü–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫": "supplier",
    "–†–µ–∑–∏–¥–µ–Ω—Ç": "resident",
    "DP": "cluster",             # –ú–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–ª–∏ DP –≤ cluster
    "–†–æ–∑—Ö—ñ–¥, –∫—ñ–ª.": "sales_qty",
    "–†–æ–∑—Ö—ñ–¥ —Ü.—Ä., –≥—Ä–Ω.": "sales_sum",
    "–ó–∞–ª–∏—à–æ–∫, –∫—ñ–ª.": "stock_qty",
    "–ó–∞–ª–∏—à–æ–∫, –≥—Ä–Ω.": "stock_sum"
}

class ImporterService:
    async def import_file(self, file_path: str):
        """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —ñ–º–ø–æ—Ä—Ç—É"""
        try:
            # 1. –ß–∏—Ç–∞—î–º–æ —Ñ–∞–π–ª (–≤–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç)
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            else:
                df = pd.read_excel(file_path)

            # 2. –ß–∏—Å—Ç–∏–º–æ —ñ –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î–º–æ
            # –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏, –¥–µ –Ω–µ–º–∞—î –ê—Ä—Ç–∏–∫—É–ª–∞
            df = df.dropna(subset=['–ê—Ä—Ç–∏–∫—É–ª'])
            
            # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó: –í—ñ–¥–¥—ñ–ª / –ì—Ä—É–ø–∞ / –ü—ñ–¥–≥—Ä—É–ø–∞
            # (–ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—É—Å—Ç–∏–º–∏ —Ä—è–¥–∫–∞–º–∏)
            df = df.fillna('')
            df['category_path'] = df['–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç'].astype(str) + "/" + \
                                  df['–ì—Ä—É–ø–∞'].astype(str) + "/" + \
                                  df['–ü—ñ–¥–≥—Ä—É–ø–∞'].astype(str)

            # –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î–º–æ –∫–æ–ª–æ–Ω–∫–∏
            df = df.rename(columns=COLUMN_MAPPING)

            # –ó–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ç—ñ –∫–æ–ª–æ–Ω–∫–∏, —è–∫—ñ —î –≤ –Ω–∞—à—ñ–π –±–∞–∑—ñ
            valid_cols = list(COLUMN_MAPPING.values()) + ['category_path']
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—Å—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑–Ω–∞–π—à–ª–∏—Å—å (—â–æ–± –Ω–µ –≤–ø–∞—Å—Ç–∏)
            available_cols = [c for c in valid_cols if c in df.columns]
            df = df[available_cols]

            # 3. –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –¥–∞–Ω—ñ –¥–ª—è SQL
            # –ê—Ä—Ç–∏–∫—É–ª –º–∞—î –±—É—Ç–∏ —Ä—è–¥–∫–æ–º
            df['article'] = df['article'].astype(str)
            # –ß–∏—Å–ª–∞ –º–∞—é—Ç—å –±—É—Ç–∏ —á–∏—Å–ª–∞–º–∏ (–∑–∞–º—ñ–Ω—é—î–º–æ –∫–æ–º–∏ –Ω–∞ –∫—Ä–∞–ø–∫–∏, —è–∫—â–æ —Ç—Ä–µ–±–∞, —ñ –Ω—É–ª—ñ)
            numeric_cols = ['sales_qty', 'sales_sum', 'stock_qty', 'stock_sum', 'department']
            for col in numeric_cols:
                if col in df.columns:
                    # –í–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–±—ñ–ª–∏, –∑–∞–º—ñ–Ω—é—î–º–æ –∫–æ–º–∏
                    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.').replace('', '0'), errors='coerce').fillna(0)

            records = df.to_dict('records')
            total = len(records)
            logging.info(f"üìä –ó—á–∏—Ç–∞–Ω–æ {total} —Ä—è–¥–∫—ñ–≤. –ü–æ—á–∏–Ω–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤ –ë–î...")

            # 4. –í–∏–∫–æ–Ω—É—î–º–æ Upsert (–í—Å—Ç–∞–≤–∫–∞ –∞–±–æ –û–Ω–æ–≤–ª–µ–Ω–Ω—è)
            # –†–æ–±–∏–º–æ —Ü–µ –ø–∞—á–∫–∞–º–∏ (batch), —â–æ–± –Ω–µ –≤–±–∏—Ç–∏ –ø–∞–º'—è—Ç—å
            batch_size = 1000
            for i in range(0, total, batch_size):
                batch = records[i:i + batch_size]
                await self._insert_batch(batch)
                logging.info(f"   Processed {min(i + batch_size, total)}/{total}")

            return total

        except Exception as e:
            logging.error(f"Import Error: {e}")
            raise e

    async def _insert_batch(self, batch):
        """SQL –º–∞–≥—ñ—è –¥–ª—è –º–∞—Å–æ–≤–æ—ó –≤—Å—Ç–∞–≤–∫–∏"""
        # –§–æ—Ä–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω—å
        values = []
        for row in batch:
            values.append((
                row.get('article'), row.get('name'), int(row.get('department', 0)),
                row.get('category_path'), row.get('supplier'), row.get('resident'),
                row.get('cluster'), 
                float(row.get('sales_qty', 0)), float(row.get('sales_sum', 0)),
                float(row.get('stock_qty', 0)), float(row.get('stock_sum', 0))
            ))

        query = """
            INSERT INTO products (
                article, name, department, category_path, supplier, resident, cluster,
                sales_qty, sales_sum, stock_qty, stock_sum, updated_at
            )
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, CURRENT_TIMESTAMP)
            ON CONFLICT (article) DO UPDATE SET
                name = EXCLUDED.name,
                sales_qty = EXCLUDED.sales_qty,
                sales_sum = EXCLUDED.sales_sum,
                stock_qty = EXCLUDED.stock_qty,
                stock_sum = EXCLUDED.stock_sum,
                cluster = EXCLUDED.cluster,
                updated_at = CURRENT_TIMESTAMP;
        """
        # executemany –ø—Ä–∞—Ü—é—î —à–≤–∏–¥–∫–æ
        await db.pool.executemany(query, values)

importer = ImporterService()